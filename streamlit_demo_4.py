#!/usr/bin/env python3
"""
ã‚³ãƒ”ãƒ¼ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ - æ®µéšçš„ç”Ÿæˆå¯¾å¿œç‰ˆ
"""

import streamlit as st
import openai
import pandas as pd
from typing import List, Dict, Tuple
import os

# APIã‚­ãƒ¼è¨­å®šï¼ˆStreamlit Secretså¯¾å¿œï¼‰
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
except:
    # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-proj-your-api-key-here")

# æ®µéšçš„ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾©
STAGED_PROMPTS = [
    {
        "stage": 1,
        "title": "ğŸ¯ æ§‹é€ åŒ–ç”Ÿæˆ",
        "prompt": "ç”Ÿæ´»è€…ã«ã¨ã£ã¦æ–°ã—ã„ä¾¡å€¤ã‚’ç™ºè¦‹ã§ãã‚‹what to say ã‚’ï¼’ï¼æ¡ˆè€ƒãˆã¦ã€ãã®ä¸Šã§äºŒåå€‹ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã›ã‚ˆã€‚\n\nâ€»ã€Œwhat to sayã€ã¨ã¯ã€Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä½•ã‹ã€ã‚ã‚‹ã„ã¯ã€ãã®ä¼ç”»ã‚’é€šã—ã¦ã€Œä½•ã‚’æ®‹ã™ã®ã‹ã€ã€Œä½•ã‚’æŒã¡å¸°ã£ã¦ã‚‚ã‚‰ã†ã®ã‹ã€ã¨ã„ã†æ„å‘³ã§ã™ã€‚\n\nå‰ç½®ãã‚„èª¬æ˜æ–‡ã¯ä¸è¦ã€‚ã‚³ãƒ”ãƒ¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
        "description": "20å€‹ã®what to sayã¨20å€‹ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ"
    },
    {
        "stage": 2,
        "title": "âš¡ å¼·åŒ–ãƒ»æ”¹å–„",
        "prompt": "ã©ã‚Œã‚‚åºƒå‘Šçš„ã§å¿ƒãŒå‹•ã‹ãªã„ã€ã‚‚ã£ã¨å¼·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¿…è¦ã€‚ä½¿ã„å¤ã•ã‚ŒãŸè¨€ã„å›ã—ã‚’ä½¿ã‚ãšã«ã€å®šå‹çš„ãªæ§‹æ–‡ã¯é¿ã‘ã¦ã€‚äºŒåå€‹ã®ã‚³ãƒ”ãƒ¼ã‚’è€ƒãˆã¦\n\nå‰ç½®ãã‚„èª¬æ˜æ–‡ã¯ä¸è¦ã€‚ã‚³ãƒ”ãƒ¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
        "description": "ã‚ˆã‚Šå¼·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«æ”¹å–„ã—ã¾ã™"
    },
    {
        "stage": 3,
        "title": "âœ¨ æœ€çµ‚æ´—ç·´",
        "prompt": "æœ€çµ‚çš„ãªäºŒåå€‹ã®æ¡ˆã‚’ãã‚Œãã‚Œæ„å‘³ãŒå‡ç¸®ã™ã‚‹ã‚ˆã†ã«ã€çŸ­ã„è¨€è‘‰ã«ãƒªãƒ•ãƒ¬ãƒ¼ã‚ºã—ã¦\n\nå‰ç½®ãã‚„èª¬æ˜æ–‡ã¯ä¸è¦ã€‚ã‚³ãƒ”ãƒ¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
        "description": "æ„å‘³ã‚’å‡ç¸®ã—ãŸçŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã«æœ€çµ‚èª¿æ•´"
    }
]

def get_available_models() -> List[str]:
    """åˆ©ç”¨å¯èƒ½ãªOpenAIãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        openai.api_key = OPENAI_API_KEY
        models = openai.models.list()
        # GPTãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆãƒãƒ£ãƒƒãƒˆç”¨ï¼‰
        gpt_models = []
        for model in models.data:
            model_id = model.id
            if any(prefix in model_id.lower() for prefix in ['gpt-', 'o1-', 'o3-']):
                gpt_models.append(model_id)
        
        # ã‚½ãƒ¼ãƒˆã—ã¦è¿”ã™
        return sorted(gpt_models, reverse=True)
    except Exception as e:
        st.sidebar.error(f"ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’è¿”ã™
        return get_default_models()

def get_default_models() -> List[str]:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ"""
    return [
        "gpt-4.1",
        "gpt-4o",
        "gpt-4o-mini"
    ]

def clean_response(response: str) -> str:
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å†—é•·ãªå‰ç½®ãã‚’é™¤å»"""
    # ä¸€èˆ¬çš„ãªå‰ç½®ããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
    patterns_to_remove = [
        r"^ã‚‚ã¡ã‚ã‚“ã§ã™[ã€‚ï¼]*\s*",
        r"^æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸ[ã€‚ï¼]*\s*",
        r"^ä»¥ä¸‹ã®ã‚ˆã†ãª.*?ã§ã™[ã€‚ï¼]*\s*",
        r"^.*?ã‚’æ„è­˜ã—ã¦.*?ã—ã¾ã™[ã€‚ï¼]*\s*",
        r"^.*?å†ç·¨é›†ã—ã¾ã™[ã€‚ï¼]*\s*",
        r"^.*?ä½œæˆã—ã¾ã™[ã€‚ï¼]*\s*",
        r"^.*?ã«å†ç·¨é›†ã—ã¾ã™[ã€‚ï¼]*\s*"
    ]
    
    import re
    cleaned = response
    for pattern in patterns_to_remove:
        cleaned = re.sub(pattern, "", cleaned, flags=re.MULTILINE)
    
    # å…ˆé ­ã®ç©ºè¡Œã‚’é™¤å»
    cleaned = cleaned.lstrip('\n')
    
    return cleaned

def get_model_categories() -> Dict[str, Dict]:
    """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†"""
    return {
        "ğŸ¯ æ¨™æº–GPTãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨å¥¨ï¼‰": {
            "gpt-4o": {
                "price": "$2.50/$10",
                "description": "ğŸ¯ æœ€æ–°GPT-4ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ãƒ»å®‰å®šï¼‰",
                "use_case": "ä¸€èˆ¬çš„ãªã‚³ãƒ”ãƒ¼ç”Ÿæˆ",
                "recommended": True,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)"
            },
            "gpt-4o-mini": {
                "price": "$0.15/$0.60",
                "description": "ğŸ’¨ è»½é‡ç‰ˆGPT-4ï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰",
                "use_case": "å¤§é‡å‡¦ç†ã€é«˜é€Ÿç”Ÿæˆ",
                "recommended": True,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)"
            },
            "gpt-4.1": {
                "price": "ä¾¡æ ¼æœªå…¬é–‹",
                "description": "ğŸ†• æ¬¡ä¸–ä»£GPTï¼ˆãƒ™ãƒ¼ã‚¿ç‰ˆï¼‰",
                "use_case": "æœ€æ–°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ",
                "recommended": False,
                "note": "âš ï¸ ãƒ™ãƒ¼ã‚¿ç‰ˆãƒ»è¦æ¤œè¨¼"
            }
        }
    }

def display_model_selector() -> Tuple[str, str]:
    """ãƒ¢ãƒ‡ãƒ«é¸æŠUIã‚’è¡¨ç¤º"""
    st.sidebar.header("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    available_models = get_available_models()
    model_categories = get_model_categories()
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠæ–¹å¼ã‚’é¸ã¶
    selection_mode = st.sidebar.radio(
        "é¸æŠæ–¹å¼",
        ["ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠ", "å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è¦§"],
        help="æ¨å¥¨ã¯ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠã§ã™"
    )
    
    selected_model = None
    model_info = ""
    
    if selection_mode == "ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠ":
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠ
        st.sidebar.markdown("### ğŸ“‹ ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ†ã‚´ãƒª")
        
        for category, models in model_categories.items():
            with st.sidebar.expander(category, expanded=True):
                for model_id, model_data in models.items():
                    if model_id in available_models:
                        # æ¨å¥¨ãƒãƒ¼ã‚¯ã‚’è¿½åŠ 
                        display_name = f"â­ {model_id}" if model_data.get('recommended') else model_id
                        
                        if st.button(
                            f"{display_name}",
                            key=f"select_{model_id}",
                            help=f"{model_data['description']}\nä¾¡æ ¼: {model_data['price']}\nç”¨é€”: {model_data['use_case']}"
                        ):
                            selected_model = model_id
                            model_info = model_data['description']
                            st.session_state.selected_model = model_id
                            st.session_state.model_info = model_info
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        if 'selected_model' in st.session_state:
            selected_model = st.session_state.selected_model
            model_info = st.session_state.get('model_info', '')
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠ
            if "gpt-4.1" in available_models:
                selected_model = "gpt-4.1"
                model_info = "ğŸ†• æ¬¡ä¸–ä»£GPTï¼ˆãƒ™ãƒ¼ã‚¿ç‰ˆï¼‰"
            elif "gpt-4o" in available_models:
                selected_model = "gpt-4o"
                model_info = "ğŸ¯ æœ€æ–°GPT-4ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ãƒ»å®‰å®šï¼‰"
            elif "gpt-4o-mini" in available_models:
                selected_model = "gpt-4o-mini"
                model_info = "ğŸ’¨ è»½é‡ç‰ˆGPT-4ï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰"
            else:
                selected_model = available_models[0]
                model_info = "é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±"
            st.session_state.selected_model = selected_model
            st.session_state.model_info = model_info
    
    else:
        # å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è¦§é¸æŠ
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ±ºå®š
        default_index = 0
        if "gpt-4.1" in available_models:
            default_index = available_models.index("gpt-4.1")
        elif "gpt-4o" in available_models:
            default_index = available_models.index("gpt-4o")
        elif "gpt-4o-mini" in available_models:
            default_index = available_models.index("gpt-4o-mini")
        
        selected_model = st.sidebar.selectbox(
            "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            available_models,
            index=default_index
        )
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’æ¤œç´¢
        for category, models in model_categories.items():
            if selected_model in models:
                model_info = models[selected_model]['description']
                break
        else:
            model_info = "é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±"
    
    # ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
    if selected_model:
        st.sidebar.success(f"âœ… é¸æŠä¸­: **{selected_model}**")
    
    return selected_model, model_info

def load_conversation_history(csv_file: str = None) -> List[Dict[str, str]]:
    """CSVã‹ã‚‰ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã€OpenAI APIå½¢å¼ã«å¤‰æ›"""
    if not csv_file:
        return []
        
    try:
        df = pd.read_csv(csv_file)
        # NaNå€¤ã‚’å‰Šé™¤
        df = df.dropna()
        messages = []
        
        for _, row in df.iterrows():
            role = "user" if row['side'] == 'human' else "assistant"
            content = str(row['prompt']).strip()
            
            # ç©ºæ–‡å­—åˆ—ã‚„NaNã‚’ã‚¹ã‚­ãƒƒãƒ—
            if content and content != 'nan':
                messages.append({"role": role, "content": content})
        
        return messages
    except FileNotFoundError:
        st.warning(f"{csv_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å±¥æ­´ãªã—ã§ç¶šè¡Œã—ã¾ã™ã€‚")
        return []
    except Exception as e:
        st.error(f"å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def generate_staged_copy(orientation: str, stage_prompt: str, conversation_messages: List[Dict], model: str = "gpt-4o", temperature: float = 0.9) -> str:
    """æ®µéšçš„ã‚³ãƒ”ãƒ¼ç”Ÿæˆ"""
    openai.api_key = OPENAI_API_KEY
    
    # ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã‚’åˆ¤å®š
    is_o1_pro = "o1-pro" in model.lower()
    is_o3_or_o1_other = any(prefix in model.lower() for prefix in ['o1-', 'o3-']) and not is_o1_pro
    
    try:
        if is_o1_pro:
            # o1-proã¯Responses APIã®ã¿å¯¾å¿œ
            if conversation_messages:
                # éå»ã®ä¼šè©±ãŒã‚ã‚Œã°å«ã‚ã‚‹
                conversation_text = "\n\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_messages])
                user_message = f"""
{orientation}

éå»ã®ä¼šè©±:
{conversation_text}

{stage_prompt}
"""
            else:
                user_message = f"""
{orientation}

{stage_prompt}
"""
            
            response = openai.responses.create(
                model=model,
                input=user_message,
                reasoning={"effort": "high"}
            )
            return clean_response(response.choices[0].message.content)
            
        elif is_o3_or_o1_other:
            # ãã®ä»–ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ç”¨ã®å‡¦ç†
            if conversation_messages:
                # éå»ã®ä¼šè©±ãŒã‚ã‚Œã°å«ã‚ã‚‹
                conversation_text = "\n\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_messages])
                user_message = f"""
{orientation}

éå»ã®ä¼šè©±:
{conversation_text}

{stage_prompt}
"""
            else:
                user_message = f"""
{orientation}

{stage_prompt}
"""
            
            messages = [{"role": "user", "content": user_message}]
            
            response = openai.chat.completions.create(
                model=model,
                messages=messages,
                max_completion_tokens=1200
            )
            return response.choices[0].message.content
        
        else:
            # æ¨™æº–GPTãƒ¢ãƒ‡ãƒ«ç”¨ã®å‡¦ç†
            system_message = {
                "role": "system", 
                "content": """ã‚ãªãŸã¯å„ªç§€ãªã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
æ®µéšçš„ã«ã‚³ãƒ”ãƒ¼ã‚’æ”¹å–„ã—ã¦ã„ãã¾ã™ã€‚ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¦ã€æŒ‡ç¤ºã«å¾“ã£ã¦ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆãƒ»æ”¹å–„ã—ã¦ãã ã•ã„ã€‚

é‡è¦ï¼šå‰ç½®ãã‚„èª¬æ˜ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚ã‚³ãƒ”ãƒ¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ã€Œã‚‚ã¡ã‚ã‚“ã§ã™ã€ã€Œä»¥ä¸‹ã®ã‚ˆã†ãªã€ãªã©ã®å‰ç½®ãã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚"""
            }
            
            # æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            new_user_message = {
                "role": "user", 
                "content": f"""
{orientation}

{stage_prompt}
"""
            }
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…åˆ—ã‚’æ§‹ç¯‰ï¼ˆã‚·ã‚¹ãƒ†ãƒ  + éå»ã®ä¼šè©± + æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
            messages = [system_message] + conversation_messages + [new_user_message]
            
            response = openai.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=1200,
                temperature=temperature
            )
            return clean_response(response.choices[0].message.content)
            
    except Exception as e:
        error_msg = str(e)
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"

def generate_copy_ideas(orientation: str, csv_file: str = None, num_ideas: int = 5, model: str = "gpt-4o", temperature: float = 0.9) -> str:
    """ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ + ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ã®ã‚³ãƒ”ãƒ¼ç”Ÿæˆï¼ˆå¾“æ¥ç‰ˆï¼‰"""
    openai.api_key = OPENAI_API_KEY
    
    # ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
    conversation_history = load_conversation_history(csv_file)
    
    # ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã‚’åˆ¤å®š
    is_o1_pro = "o1-pro" in model.lower()
    is_o3_or_o1_other = any(prefix in model.lower() for prefix in ['o1-', 'o3-']) and not is_o1_pro
    
    try:
        if is_o1_pro:
            # o1-proã¯Responses APIã®ã¿å¯¾å¿œ
            user_message = f"""
{orientation}

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€åŠ¹æœçš„ãªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’{num_ideas}å€‹ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
            
            response = openai.responses.create(
                model=model,
                input=user_message,
                reasoning={"effort": "high"}  # o1-proç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            )
            # Responses APIã®æ­£ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼
            return clean_response(response.choices[0].message.content)
            
        elif is_o3_or_o1_other:
            # ãã®ä»–ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆo1ã€o3-miniç­‰ï¼‰ç”¨ã®å‡¦ç†
            user_message = f"""
{orientation}

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€åŠ¹æœçš„ãªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’{num_ideas}å€‹ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
            
            # æ¨è«–ãƒ¢ãƒ‡ãƒ«ã¯å±¥æ­´ã‚’å«ã‚ãšã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿
            messages = [{"role": "user", "content": user_message}]
            
            response = openai.chat.completions.create(
                model=model,
                messages=messages,
                max_completion_tokens=1200
                # temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„
            )
            return clean_response(response.choices[0].message.content)
        
        else:
            # æ¨™æº–GPTãƒ¢ãƒ‡ãƒ«ç”¨ã®å‡¦ç†
            system_message = {
                "role": "system", 
                "content": """ã‚ãªãŸã¯å„ªç§€ãªã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¦ã€ä¸ãˆã‚‰ã‚ŒãŸã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æ´»ç”¨ã—ã€åŠ¹æœçš„ãªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯ç°¡æ½”ã§ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã‚ã‚Šã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«åˆºã•ã‚‹ã‚‚ã®ã‚’5å€‹å³é¸ã—ã¦ãã ã•ã„ã€‚
é‡è¦ï¼šå‰ç½®ãã‚„èª¬æ˜ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚ã‚³ãƒ”ãƒ¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ã€Œã‚‚ã¡ã‚ã‚“ã§ã™ã€ã€Œä»¥ä¸‹ã®ã‚ˆã†ãªã€ãªã©ã®å‰ç½®ãã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚"""
            }
            
            # æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            new_user_message = {
                "role": "user", 
                "content": f"""
{orientation}

æœ€çµ‚çš„ã«{num_ideas}å€‹ã®å³é¸ã•ã‚ŒãŸã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
            }
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…åˆ—ã‚’æ§‹ç¯‰
            messages = [system_message] + conversation_history + [new_user_message]
            
            response = openai.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=1200,
                temperature=temperature
            )
            return clean_response(response.choices[0].message.content)
            
    except Exception as e:
        error_msg = str(e)
        
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"

# Streamlit UI
st.set_page_config(
    page_title="ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã«ãªã‚ã†",
    page_icon="ğŸ‘¨",
    layout="wide"
)

st.title("ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã«ãªã‚ã†ğŸ‘¨")
st.markdown("æ®µéšçš„ã«ã‚³ãƒ”ãƒ¼ã‚’æ”¹å–„ã—ã¦ã„ãã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å„æ®µéšã®çµæœãŒè“„ç©ã•ã‚Œã¾ã™ã€‚")

st.markdown("---")

# ãƒ¢ãƒ‡ãƒ«é¸æŠ
selected_model, model_info = display_model_selector()

st.sidebar.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - Temperatureè¨­å®š
st.sidebar.header("ğŸ¯ ãƒã‚¸ãƒ¡ãƒ¬ãƒ™ãƒ«")
temperature = st.sidebar.slider(
    "èª¿æ•´",
    min_value=0.0,
    max_value=1.5,
    value=1.2,
    step=0.1,
    help="0.0: ã¨ã¦ã‚‚ãƒã‚¸ãƒ¡ â† â†’ 1.5: ã¨ã¦ã‚‚ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–"
)



st.sidebar.markdown("---")

# ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰é¸æŠ
st.sidebar.header("ğŸ›ï¸ ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰")
generation_mode = st.sidebar.radio(
    "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
    ["æ®µéšçš„ç”Ÿæˆ", "ä¸€æ‹¬ç”Ÿæˆ"],
    help="æ®µéšçš„ç”Ÿæˆï¼š4æ®µéšã§æ”¹å–„\nä¸€æ‹¬ç”Ÿæˆï¼šå¾“æ¥ã®ä¸€åº¦ã§ç”Ÿæˆ"
)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
if generation_mode == "æ®µéšçš„ç”Ÿæˆ":
    # æ®µéšçš„ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'staged_results' not in st.session_state:
        st.session_state.staged_results = {}
    if 'staged_conversation' not in st.session_state:
        st.session_state.staged_conversation = []
    if 'staged_orientation' not in st.session_state:
        st.session_state.staged_orientation = ""
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“‹ ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å…¥åŠ›")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        default_orientation = """ã€èª²é¡Œå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã®è¨´æ±‚ã—ãŸã„ãƒã‚¤ãƒ³ãƒˆã€‘
ãƒ«ã‚¤ãƒœã‚¹ã¨ã‚°ãƒªãƒ¼ãƒ³ãƒ«ã‚¤ãƒœã‚¹ã®2ç¨®ã®èŒ¶è‘‰ã‚’ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã‚‰ã—ã„è±Šã‹ãªé¦™ã‚Šç«‹ã¡ãŒã‚ã‚ŠãªãŒã‚‰ã€ã™ã£ãã‚Šã¨ã—ãŸé£²ã¿ã‚„ã™ã•ã‚’å®Ÿç¾ã€‚ã‚¯ã‚»ã®ã‚ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã§ã™ãŒã€ã™ã£ãã‚Šã‚´ã‚¯ã‚´ã‚¯é£²ã‚ã‚‹å‘³ã‚ã„ã§ã™ã€‚ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ç‰¹å®šåŸææ–™ç­‰28å“ç›®ä¸ä½¿ç”¨ã€ã‚«ãƒ•ã‚§ã‚¤ãƒ³ã‚¼ãƒ­ãªã®ã«ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®è±Šã‹ãªé¦™ã‚Šã§ã™ã£ãã‚Šãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã€‚ä»•äº‹ä¸­ã€é£Ÿä¸­é£Ÿå¾Œã€å–‰ãŒæ¸‡ã„ãŸã¨ããªã©ã•ã¾ã–ã¾ãªã‚·ãƒ¼ãƒ³ã§ãŠã™ã™ã‚ã§ã™ã€‚

ã€ä»Šå›ã€å‹Ÿé›†ã™ã‚‹ä½œå“ã«æœŸå¾…ã™ã‚‹ã“ã¨ã€‘
ã€ŒGREEN DAãƒ»KAãƒ»RAã€ã¯"ã‚„ã•ã—ã•"ã‚’å¤§äº‹ã«ã—ãŸå¿ƒã¨ã‚«ãƒ©ãƒ€ã«ã‚„ã•ã—ã„ãƒ–ãƒ©ãƒ³ãƒ‰ã§ã™ã€‚æ•°ã‚ã‚‹ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®ä¸­ã§ã‚‚ã€ã€ŒGREEN DAãƒ»KAãƒ»RA ã‚„ã•ã—ã„ãƒ«ã‚¤ãƒœã‚¹ã€ã‚’é¸ã³ãŸããªã‚‹ã€ã‚„ã•ã—ã•ã®ã¤ã¾ã£ãŸè¡¨ç¾ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚

ã€åˆ¶ä½œã«ã‚ãŸã£ã¦ã®æ³¨æ„äº‹é …ã€‘
ã€ŒGREEN DAãƒ»KAãƒ»RAãƒ–ãƒ©ãƒ³ãƒ‰ã®æ„›å¬Œã‚’å¤§åˆ‡ã«ã—ãªãŒã‚‰è¡¨ç¾ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚ã€ŒGREEN DAãƒ»KAãƒ»RAã€ã¯"ã‚„ã•ã—ã•"ã‚’å¤§äº‹ã«ã—ãŸå¿ƒã¨ã‚«ãƒ©ãƒ€ã«ã‚„ã•ã—ã„ãƒ–ãƒ©ãƒ³ãƒ‰ã§ã™ã€‚æ•°ã‚ã‚‹ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®ä¸­ã§ã‚‚ã€ã€ŒGREEN DAãƒ»KAãƒ»RA ã‚„ã•ã—ã„ãƒ«ã‚¤ãƒœã‚¹ã€ã‚’é¸ã³ãŸããªã‚‹ã€ã‚„ã•ã—ã•ã®ã¤ã¾ã£ãŸè¡¨ç¾ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚ä»Šå›ã®ãŠé¡Œã§ã¯ã€ã•ã¾ã–ã¾ãªç”Ÿæ´»ã‚·ãƒ¼ãƒ³ã§æ°´åˆ†è£œçµ¦ã‚’ã™ã‚‹20~30ä»£ç”·å¥³ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¾ã™ã€‚ãƒ«ã‚¤ãƒœã‚¹ã¨ã‚°ãƒªãƒ¼ãƒ³ãƒ«ã‚¤ãƒœã‚¹ã®2ç¨®ã®èŒ¶è‘‰ã‚’ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã‚‰ã—ã„è±Šã‹ãªé¦™ã‚Šç«‹ã¡ãŒã‚ã‚ŠãªãŒã‚‰ã€ã™ã£ãã‚Šã¨ã—ãŸé£²ã¿ã‚„ã™ã•ã‚’å®Ÿç¾ã€‚ã‚¯ã‚»ã®ã‚ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã§ã™ãŒã€ã™ã£ãã‚Šã‚´ã‚¯ã‚´ã‚¯é£²ã‚ã‚‹å‘³ã‚ã„ã§ã™ã€‚ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ç‰¹å®šåŸææ–™ç­‰28å“ç›®ä¸ä½¿ç”¨ã€ã‚«ãƒ•ã‚§ã‚¤ãƒ³ã‚¼ãƒ­ãªã®ã«ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®è±Šã‹ãªé¦™ã‚Šã§ã™ã£ãã‚Šãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã€‚ä»•äº‹ä¸­ã€é£Ÿä¸­é£Ÿå¾Œã€å–‰ãŒæ¸‡ã„ãŸã¨ããªã©ã•ã¾ã–ã¾ãªã‚·ãƒ¼ãƒ³ã§ãŠã™ã™ã‚ã§ã™ã€‚ã€ŒGREEN DAãƒ»KAãƒ»RAã€ãƒ–ãƒ©ãƒ³ãƒ‰ã®æ„›å¬Œã‚’å¤§åˆ‡ã«ã—ãªãŒã‚‰è¡¨ç¾ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"""
        
        # ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å…¥åŠ›ã‚¨ãƒªã‚¢
        orientation = st.text_area(
            "ä¼æ¥­æƒ…å ±ãƒ»èª²é¡Œãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç­‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            value=st.session_state.get('staged_orientation', default_orientation),
            height=300
        )
        
        # æ®µéšçš„ç”Ÿæˆã®é€²è¡ŒçŠ¶æ³
        st.markdown("### ğŸš€ æ®µéšçš„ç”Ÿæˆï¼ˆä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ï¼‰")
        
        # å®Œäº†çŠ¶æ³ã‚’è¡¨ç¤º
        completed_stages = len(st.session_state.staged_results)
        total_stages = len(STAGED_PROMPTS)
        st.markdown(f"**å®Œäº†çŠ¶æ³**: {completed_stages}/{total_stages} æ®µéšå®Œäº†")
        
        # å„æ®µéšã®ãƒœã‚¿ãƒ³ï¼ˆã™ã¹ã¦ã„ã¤ã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰
        for i, stage_info in enumerate(STAGED_PROMPTS):
            stage_num = stage_info['stage']
            
            # ãƒœã‚¿ãƒ³ã®çŠ¶æ…‹ã‚’æ±ºå®šï¼ˆã™ã¹ã¦å®Ÿè¡Œå¯èƒ½ï¼‰
            if stage_num in st.session_state.staged_results:
                # æ—¢ã«å®Ÿè¡Œæ¸ˆã¿
                button_label = f"ğŸ”„ {stage_info['title']} (å†å®Ÿè¡Œ)"
                button_type = "secondary"
            else:
                # æœªå®Ÿè¡Œ
                button_label = f"â–¶ï¸ {stage_info['title']}"
                button_type = "primary"
            
            col_btn, col_desc = st.columns([1, 2])
            with col_btn:
                if st.button(
                    button_label,
                    key=f"stage_{stage_num}",
                    type=button_type
                ):
                    if not orientation:
                        st.error("ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    else:
                        # ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                        st.session_state.staged_orientation = orientation
                        
                        # åˆæœŸåŒ–ï¼ˆå±¥æ­´ãªã—ï¼‰
                        if not st.session_state.staged_conversation:
                            st.session_state.staged_conversation = []
                        
                        with st.spinner(f"{stage_info['title']}ã‚’ç”Ÿæˆä¸­... (ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {selected_model})"):
                            result = generate_staged_copy(
                                orientation, 
                                stage_info['prompt'], 
                                st.session_state.staged_conversation,
                                selected_model,
                                temperature
                            )
                            
                        # çµæœã‚’ä¿å­˜
                        st.session_state.staged_results[stage_num] = result
                        
                        # ä¼šè©±å±¥æ­´ã«è¿½åŠ ã¾ãŸã¯æ›´æ–°
                        # æ—¢å­˜ã®åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        found_existing = False
                        for j, msg in enumerate(st.session_state.staged_conversation):
                            if (msg['role'] == 'user' and 
                                msg['content'] == stage_info['prompt']):
                                # æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¦‹ã¤ã‹ã£ãŸå ´åˆã€æ¬¡ã®assistantå¿œç­”ã‚’æ›´æ–°
                                if j + 1 < len(st.session_state.staged_conversation):
                                    st.session_state.staged_conversation[j + 1]['content'] = result
                                else:
                                    st.session_state.staged_conversation.append({
                                        "role": "assistant", 
                                        "content": result
                                    })
                                found_existing = True
                                break
                        
                        if not found_existing:
                            # æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å ´åˆã€è¿½åŠ 
                            st.session_state.staged_conversation.append({
                                "role": "user", 
                                "content": stage_info['prompt']
                            })
                            st.session_state.staged_conversation.append({
                                "role": "assistant", 
                                "content": result
                            })
                        
                        st.rerun()
            
            with col_desc:
                st.markdown(f"*{stage_info['description']}*")
        
        # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
        if len(st.session_state.staged_results) > 0:
            if st.button("ğŸ”„ æ®µéšçš„ç”Ÿæˆã‚’ãƒªã‚»ãƒƒãƒˆ", type="secondary"):
                st.session_state.staged_results = {}
                st.session_state.staged_conversation = []
                st.session_state.staged_orientation = ""
                st.rerun()
    
    with col2:
        st.subheader("âœ¨ ç”Ÿæˆçµæœ")
        
        # æœ€æ–°ã®çµæœã®ã¿ã‚’è¡¨ç¤º
        if st.session_state.staged_results:
            # æœ€æ–°ã®æ®µéšã‚’å–å¾—ï¼ˆæœ€ã‚‚å¤§ãã„æ®µéšç•ªå·ï¼‰
            latest_stage = max(st.session_state.staged_results.keys())
            latest_result = st.session_state.staged_results[latest_stage]
            stage_info = STAGED_PROMPTS[latest_stage - 1]
            
            st.markdown(f"**ç¾åœ¨ã®æ®µéš**: {stage_info['title']}")
            st.text_area(
                "ç”Ÿæˆçµæœ",
                value=latest_result,
                height=400,
                key="current_result_display"
            )
            
            # ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã§é…ç½®
            col_download, col_reflect = st.columns([1, 1])
            
            with col_download:
                # çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                st.download_button(
                    label="ğŸ“„ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=latest_result,
                    file_name=f"copy_result.txt",
                    mime="text/plain"
                )
            
            with col_reflect:
                # è‡ªçœå†ç”Ÿæˆãƒœã‚¿ãƒ³
                if st.button(
                    "ğŸ¤” è‡ªçœã—ã¦å†ç”Ÿæˆ",
                    help="ç¾åœ¨ã®çµæœã‚’è‡ªçœãƒ»æ”¹å–„ã—ã¦ã‚ˆã‚Šè‰¯ã„ã‚³ãƒ”ãƒ¼ã‚’ç”Ÿæˆã—ã¾ã™"
                ):
                    # è‡ªçœãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                    reflect_prompt = f"""
ã“ã‚Œã¾ã§ã®çµæœã‚’è‡ªçœã—ã¦ãã ã•ã„ï¼š

{latest_result}

ä¸Šè¨˜ã®çµæœã‚’å®¢è¦³çš„ã«åˆ†æã—ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰æ”¹å–„ã—ã¦ãã ã•ã„ï¼š
1. ã‚ˆã‚Šå°è±¡çš„ã§è¨˜æ†¶ã«æ®‹ã‚‹ã‹
2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«åˆºã•ã‚‹è¡¨ç¾ã«ãªã£ã¦ã„ã‚‹ã‹  
3. ç‹¬å‰µæ€§ã¨èª¬å¾—åŠ›ã®ãƒãƒ©ãƒ³ã‚¹ã¯é©åˆ‡ã‹
4. ç°¡æ½”ã§åŠ›å¼·ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãªã£ã¦ã„ã‚‹ã‹

è‡ªçœã®çµæœã‚’è¸ã¾ãˆã€æ”¹å–„ã•ã‚ŒãŸã‚³ãƒ”ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
"""
                    
                    with st.spinner(f"è‡ªçœã—ã¦å†ç”Ÿæˆä¸­... (ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {selected_model})"):
                        # è‡ªçœã«ã‚ˆã‚‹å†ç”Ÿæˆ
                        reflected_result = generate_staged_copy(
                            st.session_state.staged_orientation,
                            reflect_prompt,
                            st.session_state.staged_conversation,
                            selected_model,
                            temperature
                        )
                        
                        # çµæœã‚’æ›´æ–°
                        st.session_state.staged_results[latest_stage] = reflected_result
                        
                        # ä¼šè©±å±¥æ­´ã‚‚æ›´æ–°ï¼ˆæœ€æ–°ã®çµæœã§ç½®ãæ›ãˆï¼‰
                        # è©²å½“æ®µéšã®assistantå¿œç­”ã‚’æ¢ã—ã¦æ›´æ–°
                        for i, msg in enumerate(st.session_state.staged_conversation):
                            if (msg['role'] == 'assistant' and 
                                i > 0 and 
                                st.session_state.staged_conversation[i-1]['content'] == stage_info['prompt']):
                                st.session_state.staged_conversation[i]['content'] = reflected_result
                                break
                        
                        st.success("è‡ªçœå†ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        st.rerun()
        else:
            st.info("ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…¥åŠ›ã—ã¦ã€æ®µéšçš„ç”Ÿæˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

else:
    # ä¸€æ‹¬ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆå¾“æ¥ç‰ˆï¼‰
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“‹ ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å…¥åŠ›")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        default_orientation_simple = """ã€èª²é¡Œå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã®è¨´æ±‚ã—ãŸã„ãƒã‚¤ãƒ³ãƒˆã€‘
ãƒ«ã‚¤ãƒœã‚¹ã¨ã‚°ãƒªãƒ¼ãƒ³ãƒ«ã‚¤ãƒœã‚¹ã®2ç¨®ã®èŒ¶è‘‰ã‚’ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã‚‰ã—ã„è±Šã‹ãªé¦™ã‚Šç«‹ã¡ãŒã‚ã‚ŠãªãŒã‚‰ã€ã™ã£ãã‚Šã¨ã—ãŸé£²ã¿ã‚„ã™ã•ã‚’å®Ÿç¾ã€‚ã‚¯ã‚»ã®ã‚ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã§ã™ãŒã€ã™ã£ãã‚Šã‚´ã‚¯ã‚´ã‚¯é£²ã‚ã‚‹å‘³ã‚ã„ã§ã™ã€‚ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ç‰¹å®šåŸææ–™ç­‰28å“ç›®ä¸ä½¿ç”¨ã€ã‚«ãƒ•ã‚§ã‚¤ãƒ³ã‚¼ãƒ­ãªã®ã«ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®è±Šã‹ãªé¦™ã‚Šã§ã™ã£ãã‚Šãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã€‚ä»•äº‹ä¸­ã€é£Ÿä¸­é£Ÿå¾Œã€å–‰ãŒæ¸‡ã„ãŸã¨ããªã©ã•ã¾ã–ã¾ãªã‚·ãƒ¼ãƒ³ã§ãŠã™ã™ã‚ã§ã™ã€‚

ã€ä»Šå›ã€å‹Ÿé›†ã™ã‚‹ä½œå“ã«æœŸå¾…ã™ã‚‹ã“ã¨ã€‘
ã€ŒGREEN DAãƒ»KAãƒ»RAã€ã¯"ã‚„ã•ã—ã•"ã‚’å¤§äº‹ã«ã—ãŸå¿ƒã¨ã‚«ãƒ©ãƒ€ã«ã‚„ã•ã—ã„ãƒ–ãƒ©ãƒ³ãƒ‰ã§ã™ã€‚æ•°ã‚ã‚‹ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®ä¸­ã§ã‚‚ã€ã€ŒGREEN DAãƒ»KAãƒ»RA ã‚„ã•ã—ã„ãƒ«ã‚¤ãƒœã‚¹ã€ã‚’é¸ã³ãŸããªã‚‹ã€ã‚„ã•ã—ã•ã®ã¤ã¾ã£ãŸè¡¨ç¾ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚

ã€åˆ¶ä½œã«ã‚ãŸã£ã¦ã®æ³¨æ„äº‹é …ã€‘
ã€ŒGREEN DAãƒ»KAãƒ»RAãƒ–ãƒ©ãƒ³ãƒ‰ã®æ„›å¬Œã‚’å¤§åˆ‡ã«ã—ãªãŒã‚‰è¡¨ç¾ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚ã€ŒGREEN DAãƒ»KAãƒ»RAã€ã¯"ã‚„ã•ã—ã•"ã‚’å¤§äº‹ã«ã—ãŸå¿ƒã¨ã‚«ãƒ©ãƒ€ã«ã‚„ã•ã—ã„ãƒ–ãƒ©ãƒ³ãƒ‰ã§ã™ã€‚æ•°ã‚ã‚‹ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®ä¸­ã§ã‚‚ã€ã€ŒGREEN DAãƒ»KAãƒ»RA ã‚„ã•ã—ã„ãƒ«ã‚¤ãƒœã‚¹ã€ã‚’é¸ã³ãŸããªã‚‹ã€ã‚„ã•ã—ã•ã®ã¤ã¾ã£ãŸè¡¨ç¾ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚ä»Šå›ã®ãŠé¡Œã§ã¯ã€ã•ã¾ã–ã¾ãªç”Ÿæ´»ã‚·ãƒ¼ãƒ³ã§æ°´åˆ†è£œçµ¦ã‚’ã™ã‚‹20~30ä»£ç”·å¥³ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¾ã™ã€‚ãƒ«ã‚¤ãƒœã‚¹ã¨ã‚°ãƒªãƒ¼ãƒ³ãƒ«ã‚¤ãƒœã‚¹ã®2ç¨®ã®èŒ¶è‘‰ã‚’ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã‚‰ã—ã„è±Šã‹ãªé¦™ã‚Šç«‹ã¡ãŒã‚ã‚ŠãªãŒã‚‰ã€ã™ã£ãã‚Šã¨ã—ãŸé£²ã¿ã‚„ã™ã•ã‚’å®Ÿç¾ã€‚ã‚¯ã‚»ã®ã‚ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã§ã™ãŒã€ã™ã£ãã‚Šã‚´ã‚¯ã‚´ã‚¯é£²ã‚ã‚‹å‘³ã‚ã„ã§ã™ã€‚ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ç‰¹å®šåŸææ–™ç­‰28å“ç›®ä¸ä½¿ç”¨ã€ã‚«ãƒ•ã‚§ã‚¤ãƒ³ã‚¼ãƒ­ãªã®ã«ã€ãƒ«ã‚¤ãƒœã‚¹ãƒ†ã‚£ãƒ¼ã®è±Šã‹ãªé¦™ã‚Šã§ã™ã£ãã‚Šãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã€‚ä»•äº‹ä¸­ã€é£Ÿä¸­é£Ÿå¾Œã€å–‰ãŒæ¸‡ã„ãŸã¨ããªã©ã•ã¾ã–ã¾ãªã‚·ãƒ¼ãƒ³ã§ãŠã™ã™ã‚ã§ã™ã€‚ã€ŒGREEN DAãƒ»KAãƒ»RAã€ãƒ–ãƒ©ãƒ³ãƒ‰ã®æ„›å¬Œã‚’å¤§åˆ‡ã«ã—ãªãŒã‚‰è¡¨ç¾ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"""
        
        # ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å…¥åŠ›ã‚¨ãƒªã‚¢
        orientation = st.text_area(
            "ä¼æ¥­æƒ…å ±ãƒ»èª²é¡Œãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç­‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            value=default_orientation_simple,
            height=300
        )
        
        generate_button = st.button("ğŸš€ ã‚³ãƒ”ãƒ¼ç”Ÿæˆ", type="primary")

    with col2:
        st.subheader("âœ¨ ç”Ÿæˆçµæœ")
        
        if generate_button:
            if not orientation:
                st.error("ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            else:
                with st.spinner(f"ã‚³ãƒ”ãƒ¼ã‚’ç”Ÿæˆä¸­... (ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {selected_model})"):
                    result = generate_copy_ideas(orientation, None, 5, selected_model, temperature)
                    
                st.success("ç”Ÿæˆå®Œäº†ï¼")
                st.text_area("ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ”ãƒ¼", value=result, height=400)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                st.download_button(
                    label="ğŸ“„ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=result,
                    file_name="copy_ideas.txt",
                    mime="text/plain"
                )

st.sidebar.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - ç®¡ç†è€…ç”¨æ©Ÿèƒ½ã®ã¿
st.sidebar.header("ğŸ”§ ç®¡ç†è€…æ©Ÿèƒ½")
if st.sidebar.checkbox("ç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰", value=False):
    st.sidebar.markdown("---")
    st.sidebar.subheader("ç®¡ç†è€…è¨­å®š")
    
    available_models = get_available_models()
    
    if st.sidebar.button("åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ä¸€è¦§è¡¨ç¤º"):
        st.sidebar.write("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
        for model in available_models:
            st.sidebar.write(f"â€¢ {model}")
    
    if st.sidebar.button("ãƒ¢ãƒ‡ãƒ«è©³ç´°æƒ…å ±è¡¨ç¤º"):
        model_categories = get_model_categories()
        for category, models in model_categories.items():
            st.sidebar.write(f"**{category}**")
            for model_id, model_data in models.items():
                if model_id in available_models:
                    st.sidebar.write(f"â€¢ {model_id}: {model_data['price']}")
    
    if st.sidebar.button("æ®µéšçš„ç”ŸæˆçŠ¶æ…‹è¡¨ç¤º"):
        if generation_mode == "æ®µéšçš„ç”Ÿæˆ":
            st.sidebar.json({
                "total_stages": len(STAGED_PROMPTS),
                "completed_stages": len(st.session_state.get('staged_results', {})),
                "conversation_length": len(st.session_state.get('staged_conversation', [])),
                "parallel_execution": True,
                "selected_model": selected_model
            })
        else:
            st.sidebar.info("æ®µéšçš„ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        
    # APIè¨­å®šç¢ºèª
    if OPENAI_API_KEY == "sk-proj-your-api-key-here":
        st.sidebar.warning("âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
    else:
        st.sidebar.success("âœ… APIã‚­ãƒ¼ãŒè¨­å®šæ¸ˆã¿") 