#!/usr/bin/env python3
"""
Framework 5: Share of Search Analysis
Analysis Frameworks Component

å®Ÿè¡Œæ–¹æ³•:
  python src/framework_05_share_of_search.py

ç‹¬ç«‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨ã—ã¦å‹•ä½œã—ã¾ã™ã€‚
"""

import asyncio
import json
import time
import argparse
from datetime import datetime
from typing import List, Dict, Any
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys

# ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯
try:
    from pytrends.request import TrendReq
except ImportError:
    print("âŒ pytrends ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install pytrends pandas matplotlib")
    sys.exit(1)

class ShareOfSearchFramework:
    """Share of Search åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ - ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ç‰ˆ"""
    
    def __init__(self, output_base_dir: str = "output"):
        self.framework_id = 5
        self.framework_name = "Share of Search"
        self.version = "1.0.0"
        self.component_name = "framework-analysis"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå†…ã«è¨­å®š
        self.output_dir = os.path.join(
            output_base_dir,
            f"framework_05_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"ğŸš€ {self.framework_name} v{self.version}")
        print(f"ğŸ“¦ Component: {self.component_name}")
        print(f"ğŸ“ Output: {self.output_dir}")
    
    async def collect_data(self, brand_name: str, competitors: List[str], 
                          category: str, time_range: str = "today 12-m") -> Dict[str, Any]:
        """Share of Search ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»åˆ†æ"""
        
        start_time = time.time()
        print(f"\nğŸ“Š åˆ†æé–‹å§‹: {brand_name} vs {competitors}")
        
        try:
            # Step 1: Google Trends APIæ¥ç¶š
            print("ğŸ”— Google Trends APIæ¥ç¶šä¸­...")
            pytrends = TrendReq(hl='ja-JP', tz=360, timeout=(10, 25))
            
            # Step 2: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãƒ‡ãƒ¼ã‚¿å–å¾—
            all_keywords = [brand_name] + competitors
            print(f"ğŸ” æ¤œç´¢ãƒ‡ãƒ¼ã‚¿å–å¾—: {all_keywords}")
            
            pytrends.build_payload(all_keywords, timeframe=time_range, geo='JP')
            interest_data = pytrends.interest_over_time()
            
            if interest_data.empty:
                raise Exception("æ¤œç´¢ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            # Step 3: Share of Search è¨ˆç®—
            print("ğŸ§® Share of Search è¨ˆç®—ä¸­...")
            sos_data = self._calculate_share_of_search(interest_data, all_keywords)
            
            # Step 4: ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            trend_analysis = self._analyze_trends(interest_data, all_keywords)
            
            # Step 5: ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ
            competitive_analysis = self._analyze_competitive_position(sos_data, brand_name)
            
            execution_time = time.time() - start_time
            
            result = {
                "framework_info": {
                    "id": self.framework_id,
                    "name": self.framework_name,
                    "version": self.version,
                    "component": self.component_name,
                    "execution_time": execution_time,
                    "timestamp": datetime.now().isoformat()
                },
                "input_parameters": {
                    "brand_name": brand_name,
                    "competitors": competitors,
                    "category": category,
                    "time_range": time_range
                },
                "share_of_search": sos_data,
                "trend_analysis": trend_analysis,
                "competitive_analysis": competitive_analysis,
                "insights": self._generate_insights(sos_data, trend_analysis, competitive_analysis),
                "raw_data_info": {
                    "rows": len(interest_data),
                    "columns": list(interest_data.columns),
                    "date_range": {
                        "start": interest_data.index[0].isoformat() if not interest_data.empty else None,
                        "end": interest_data.index[-1].isoformat() if not interest_data.empty else None
                    }
                },
                "success": True
            }
            
            print(f"âœ… åˆ†æå®Œäº† ({execution_time:.2f}ç§’)")
            return result
            
        except Exception as e:
            error_result = {
                "framework_info": {
                    "id": self.framework_id,
                    "name": self.framework_name,
                    "component": self.component_name,
                    "error": str(e)
                },
                "success": False,
                "execution_time": time.time() - start_time
            }
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return error_result
    
    def _calculate_share_of_search(self, data: pd.DataFrame, keywords: List[str]) -> Dict[str, float]:
        """æ¤œç´¢ã‚·ã‚§ã‚¢è¨ˆç®—"""
        # NaNå€¤ã‚’0ã§ç½®æ›
        data_clean = data[keywords].fillna(0)
        
        # æœŸé–“å¹³å‡ã§ã®å„ãƒ–ãƒ©ãƒ³ãƒ‰ã‚·ã‚§ã‚¢
        total_searches = data_clean.sum(axis=1)
        share_data = {}
        
        for keyword in keywords:
            if total_searches.sum() > 0:
                share_data[keyword] = (data_clean[keyword].sum() / data_clean.sum().sum() * 100)
            else:
                share_data[keyword] = 0.0
        
        return share_data
    
    def _analyze_trends(self, data: pd.DataFrame, keywords: List[str]) -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        trends = {}
        
        for keyword in keywords:
            keyword_data = data[keyword].fillna(0)
            if len(keyword_data) > 1:
                # ç·šå½¢å›å¸°ã§å‚¾å‘è¨ˆç®—
                x = range(len(keyword_data))
                correlation = pd.Series(x).corr(keyword_data)
                
                trend_direction = "increasing" if correlation > 0.1 else "decreasing" if correlation < -0.1 else "stable"
                trend_strength = abs(correlation)
                
                trends[keyword] = {
                    "direction": trend_direction,
                    "strength": trend_strength,
                    "recent_peak": keyword_data.max(),
                    "recent_avg": keyword_data.mean()
                }
        
        return trends
    
    def _analyze_competitive_position(self, sos_data: Dict[str, float], brand_name: str) -> Dict[str, Any]:
        """ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ"""
        sorted_brands = sorted(sos_data.items(), key=lambda x: x[1], reverse=True)
        brand_rank = next((i+1 for i, (brand, _) in enumerate(sorted_brands) if brand == brand_name), None)
        
        market_leader = sorted_brands[0][0] if sorted_brands else None
        brand_share = sos_data.get(brand_name, 0)
        leader_share = sorted_brands[0][1] if sorted_brands else 0
        
        gap_to_leader = leader_share - brand_share if market_leader != brand_name else 0
        
        return {
            "brand_rank": brand_rank,
            "total_brands": len(sos_data),
            "market_leader": market_leader,
            "brand_share": brand_share,
            "leader_share": leader_share,
            "gap_to_leader": gap_to_leader,
            "competitive_intensity": len([s for s in sos_data.values() if s > 10])  # 10%ä»¥ä¸Šã®ãƒ–ãƒ©ãƒ³ãƒ‰æ•°
        }
    
    def _generate_insights(self, sos_data: Dict[str, float], 
                          trend_analysis: Dict[str, Any], 
                          competitive_analysis: Dict[str, Any]) -> List[str]:
        """æ´å¯Ÿç”Ÿæˆ"""
        insights = []
        
        # æ¤œç´¢ã‚·ã‚§ã‚¢æ´å¯Ÿ
        top_brand = max(sos_data.items(), key=lambda x: x[1])
        insights.append(f"æ¤œç´¢ã‚·ã‚§ã‚¢1ä½ã¯{top_brand[0]}ã§{top_brand[1]:.1f}%")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ´å¯Ÿ
        increasing_brands = [brand for brand, data in trend_analysis.items() 
                           if data["direction"] == "increasing" and data["strength"] > 0.3]
        if increasing_brands:
            insights.append(f"ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰: {', '.join(increasing_brands)}")
        
        # ç«¶åˆçŠ¶æ³æ´å¯Ÿ
        if competitive_analysis["competitive_intensity"] > 3:
            insights.append("æ¿€æˆ¦ã‚«ãƒ†ã‚´ãƒªï¼ˆ10%ä»¥ä¸Šã‚·ã‚§ã‚¢ãƒ–ãƒ©ãƒ³ãƒ‰å¤šæ•°ï¼‰")
        
        # ã‚®ãƒ£ãƒƒãƒ—åˆ†æ
        gap = competitive_analysis["gap_to_leader"]
        if gap > 20:
            insights.append(f"ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã„ï¼ˆ{gap:.1f}ãƒã‚¤ãƒ³ãƒˆå·®ï¼‰")
        elif gap > 0:
            insights.append(f"ãƒªãƒ¼ãƒ€ãƒ¼ã«æ¥æˆ¦ä¸­ï¼ˆ{gap:.1f}ãƒã‚¤ãƒ³ãƒˆå·®ï¼‰")
        
        return insights
    
    def save_results(self, result: Dict[str, Any]) -> None:
        """çµæœä¿å­˜"""
        try:
            # JSONçµæœä¿å­˜
            json_path = os.path.join(self.output_dir, "sos_analysis_result.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2, default=self._json_serializer)
            
            print(f"ğŸ“„ çµæœä¿å­˜: {json_path}")
            
            # å¯è¦–åŒ–
            if result["success"]:
                self._save_visualization(result)
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _json_serializer(self, obj):
        """JSON serialization helper"""
        if isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        elif hasattr(obj, 'item'):  # numpy types
            return obj.item()
        elif hasattr(obj, 'tolist'):  # numpy arrays
            return obj.tolist()
        raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
    
    def _save_visualization(self, result: Dict[str, Any]) -> None:
        """å¯è¦–åŒ–çµæœä¿å­˜"""
        try:
            sos_data = result["share_of_search"]
            
            # Share of Searchå††ã‚°ãƒ©ãƒ•
            plt.figure(figsize=(10, 8))
            
            brands = list(sos_data.keys())
            shares = list(sos_data.values())
            
            colors = plt.cm.Set3(range(len(brands)))
            
            plt.pie(shares, labels=brands, autopct='%1.1f%%', colors=colors, startangle=90)
            plt.title('Share of Search Analysis', fontsize=16, pad=20)
            plt.axis('equal')
            
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
            try:
                plt.rcParams['font.family'] = 'DejaVu Sans'
            except:
                pass
            
            chart_path = os.path.join(self.output_dir, "share_of_search_chart.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ å¯è¦–åŒ–ä¿å­˜: {chart_path}")
            
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def print_summary(self, result: Dict[str, Any]) -> None:
        """çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        if not result["success"]:
            print(f"âŒ åˆ†æå¤±æ•—: {result.get('framework_info', {}).get('error', 'Unknown error')}")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Share of Search Analysis Summary")
        print(f"{'='*60}")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æƒ…å ±
        fw_info = result["framework_info"]
        print(f"ğŸ“¦ Component: {fw_info['component']}")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {fw_info['execution_time']:.2f}ç§’")
        print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {fw_info['timestamp']}")
        
        # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params = result["input_parameters"]
        print(f"\nğŸ¯ åˆ†æå¯¾è±¡:")
        print(f"  â€¢ ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ©ãƒ³ãƒ‰: {params['brand_name']}")
        print(f"  â€¢ ç«¶åˆãƒ–ãƒ©ãƒ³ãƒ‰: {', '.join(params['competitors'])}")
        print(f"  â€¢ ã‚«ãƒ†ã‚´ãƒª: {params['category']}")
        print(f"  â€¢ æœŸé–“: {params['time_range']}")
        
        # Share of Searchçµæœ
        sos_data = result["share_of_search"]
        print(f"\nğŸ“ˆ Share of Searchçµæœ:")
        sorted_sos = sorted(sos_data.items(), key=lambda x: x[1], reverse=True)
        for i, (brand, share) in enumerate(sorted_sos, 1):
            print(f"  {i}ä½: {brand} - {share:.1f}%")
        
        # ç«¶åˆåˆ†æ
        comp_analysis = result["competitive_analysis"]
        print(f"\nğŸ† ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³:")
        print(f"  â€¢ é †ä½: {comp_analysis['brand_rank']}/{comp_analysis['total_brands']}ä½")
        print(f"  â€¢ ãƒãƒ¼ã‚±ãƒƒãƒˆãƒªãƒ¼ãƒ€ãƒ¼: {comp_analysis['market_leader']}")
        print(f"  â€¢ ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã®ã‚®ãƒ£ãƒƒãƒ—: {comp_analysis['gap_to_leader']:.1f}ãƒã‚¤ãƒ³ãƒˆ")
        
        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        insights = result["insights"]
        print(f"\nğŸ’¡ ä¸»è¦ã‚¤ãƒ³ã‚µã‚¤ãƒˆ:")
        for i, insight in enumerate(insights, 1):
            print(f"  {i}. {insight}")
        
        print(f"\nğŸ“ è©³ç´°çµæœã¯ {self.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
SAMPLE_BRAND_DATA = {
    "brand_name": "ã‚³ã‚«ã‚³ãƒ¼ãƒ©",
    "competitors": ["ãƒšãƒ—ã‚·", "åˆå¾Œã®ç´…èŒ¶", "ä¼Šå³è¡›é–€"],
    "category": "é£²æ–™",
    "time_range": "today 12-m"
}

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description='Share of Search Analysis Framework')
    parser.add_argument('--brand', type=str, default=SAMPLE_BRAND_DATA['brand_name'], help='ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ©ãƒ³ãƒ‰å')
    parser.add_argument('--competitors', nargs='+', default=SAMPLE_BRAND_DATA['competitors'], help='ç«¶åˆãƒ–ãƒ©ãƒ³ãƒ‰ãƒªã‚¹ãƒˆ')
    parser.add_argument('--category', type=str, default=SAMPLE_BRAND_DATA['category'], help='ã‚«ãƒ†ã‚´ãƒªå')
    parser.add_argument('--timerange', type=str, default=SAMPLE_BRAND_DATA['time_range'], help='æ™‚é–“ç¯„å›²')
    parser.add_argument('--output', type=str, default='output', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–
    framework = ShareOfSearchFramework(output_base_dir=args.output)
    
    print(f"ğŸ¯ ãƒ–ãƒ©ãƒ³ãƒ‰: {args.brand}")
    print(f"ğŸƒ ç«¶åˆ: {args.competitors}")
    print(f"ğŸ“‚ ã‚«ãƒ†ã‚´ãƒª: {args.category}")
    
    # åˆ†æå®Ÿè¡Œ
    result = await framework.collect_data(
        args.brand, 
        args.competitors, 
        args.category, 
        args.timerange
    )
    
    # çµæœä¿å­˜
    framework.save_results(result)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    framework.print_summary(result)

if __name__ == "__main__":
    asyncio.run(main()) 