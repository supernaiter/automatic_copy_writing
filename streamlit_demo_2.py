#!/usr/bin/env python3
"""
ã‚³ãƒ”ãƒ¼ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼
"""

import streamlit as st
import openai
import pandas as pd
from typing import List, Dict, Tuple
import os

# å›ºå®šAPIã‚­ãƒ¼è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-proj-your-api-key-here")

def get_available_models() -> List[str]:
    """åˆ©ç”¨å¯èƒ½ãªOpenAIãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        openai.api_key = OPENAI_API_KEY
        models = openai.models.list()
        # GPTãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆãƒãƒ£ãƒƒãƒˆç”¨ï¼‰
        gpt_models = []
        for model in models.data:
            model_id = model.id
            if any(prefix in model_id.lower() for prefix in ['gpt-', 'o1-', 'o3-']):
                gpt_models.append(model_id)
        
        # ã‚½ãƒ¼ãƒˆã—ã¦è¿”ã™
        return sorted(gpt_models, reverse=True)
    except Exception as e:
        st.sidebar.error(f"ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’è¿”ã™
        return get_default_models()

def get_default_models() -> List[str]:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ"""
    return [
        "o3-mini",
        "o1-pro", 
        "o1-mini",
        "o1-preview",
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-4-turbo",
        "gpt-4"
    ]

def get_model_categories() -> Dict[str, Dict]:
    """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†"""
    return {
        "ğŸ§  æ¨è«–ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨å¥¨ï¼‰": {
            "o3-mini": {
                "price": "$1.10/$4.40",
                "description": "ğŸ’° æœ€æ–°æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆé«˜æ€§èƒ½ãƒ»ä½ã‚³ã‚¹ãƒˆãƒ»æ¨å¥¨ï¼‰",
                "use_case": "ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã€è¤‡é›‘ãªæ¨è«–",
                "recommended": True,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (temperatureéå¯¾å¿œ)"
            },
            "o1-pro": {
                "price": "$150/$600",
                "description": "ğŸ§  æœ€é«˜æ€§èƒ½æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¥µã‚ã¦é«˜ä¾¡ï¼‰",
                "use_case": "æœ€é‡è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€æœ€é«˜å“è³ªè¦æ±‚",
                "recommended": False,
                "note": "âš ï¸ Responses APIã®ã¿å¯¾å¿œ (ç‰¹åˆ¥ãªå®Ÿè£…)"
            },
            "o1-mini": {
                "price": "$3/$12",
                "description": "âš¡ é«˜é€Ÿæ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰",
                "use_case": "ä¸€èˆ¬çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯",
                "recommended": False,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (temperatureéå¯¾å¿œ)"
            },
            "o1-preview": {
                "price": "$15/$60",
                "description": "ğŸ”¬ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆæ¨è«–ãƒ¢ãƒ‡ãƒ«",
                "use_case": "ãƒ†ã‚¹ãƒˆãƒ»å®Ÿé¨“ç”¨",
                "recommended": False,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (temperatureéå¯¾å¿œ)"
            }
        },
        "ğŸ¯ æ¨™æº–GPTãƒ¢ãƒ‡ãƒ«": {
            "gpt-4o": {
                "price": "$2.50/$10",
                "description": "ğŸ¯ æœ€æ–°GPT-4ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ãƒ»å®‰å®šï¼‰",
                "use_case": "ä¸€èˆ¬çš„ãªã‚³ãƒ”ãƒ¼ç”Ÿæˆ",
                "recommended": True,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)"
            },
            "gpt-4o-mini": {
                "price": "$0.15/$0.60",
                "description": "ğŸ’¨ è»½é‡ç‰ˆGPT-4ï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰",
                "use_case": "å¤§é‡å‡¦ç†ã€é«˜é€Ÿç”Ÿæˆ",
                "recommended": True,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)"
            },
            "gpt-4-turbo": {
                "price": "$10/$30",
                "description": "ğŸš€ GPT-4ã‚¿ãƒ¼ãƒœï¼ˆé«˜é€Ÿç‰ˆï¼‰",
                "use_case": "é«˜é€Ÿå‡¦ç†ãŒå¿…è¦ãªå ´åˆ",
                "recommended": False,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)"
            },
            "gpt-4": {
                "price": "$30/$60",
                "description": "ğŸ† æ¨™æº–GPT-4",
                "use_case": "åŸºæœ¬çš„ãªã‚¿ã‚¹ã‚¯",
                "recommended": False,
                "note": "âœ… Chat Completions APIå¯¾å¿œ (å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)"
            }
        },
        "ğŸ”® æœ€æ–°å®Ÿé¨“ãƒ¢ãƒ‡ãƒ«": {
            "o3-pro": {
                "price": "$20/$80",
                "description": "ğŸ”® æœ€ä¸Šä½æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆå®Ÿé¨“ç‰ˆï¼‰",
                "use_case": "æœ€é«˜å“è³ªãŒå¿…è¦ãªå ´åˆ",
                "recommended": False,
                "note": "âš ï¸ é™å®šçš„å¯¾å¿œãƒ»è¦æ¤œè¨¼"
            },
            "gpt-4.1": {
                "price": "ä¾¡æ ¼æœªå…¬é–‹",
                "description": "ğŸ†• æ¬¡ä¸–ä»£GPTï¼ˆãƒ™ãƒ¼ã‚¿ç‰ˆï¼‰",
                "use_case": "æœ€æ–°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ",
                "recommended": False,
                "note": "âš ï¸ ãƒ™ãƒ¼ã‚¿ç‰ˆãƒ»è¦æ¤œè¨¼"
            }
        }
    }

def display_model_selector() -> Tuple[str, str]:
    """ãƒ¢ãƒ‡ãƒ«é¸æŠUIã‚’è¡¨ç¤º"""
    st.sidebar.header("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    available_models = get_available_models()
    model_categories = get_model_categories()
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠæ–¹å¼ã‚’é¸ã¶
    selection_mode = st.sidebar.radio(
        "é¸æŠæ–¹å¼",
        ["ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠ", "å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è¦§"],
        help="æ¨å¥¨ã¯ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠã§ã™"
    )
    
    selected_model = None
    model_info = ""
    
    if selection_mode == "ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠ":
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠ
        st.sidebar.markdown("### ğŸ“‹ ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ†ã‚´ãƒª")
        
        for category, models in model_categories.items():
            with st.sidebar.expander(category, expanded=True):
                for model_id, model_data in models.items():
                    if model_id in available_models:
                        # æ¨å¥¨ãƒãƒ¼ã‚¯ã‚’è¿½åŠ 
                        display_name = f"â­ {model_id}" if model_data.get('recommended') else model_id
                        
                        if st.button(
                            f"{display_name}",
                            key=f"select_{model_id}",
                            help=f"{model_data['description']}\nä¾¡æ ¼: {model_data['price']}\nç”¨é€”: {model_data['use_case']}"
                        ):
                            selected_model = model_id
                            model_info = model_data['description']
                            st.session_state.selected_model = model_id
                            st.session_state.model_info = model_info
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        if 'selected_model' in st.session_state:
            selected_model = st.session_state.selected_model
            model_info = st.session_state.get('model_info', '')
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠ
            selected_model = "o3-mini" if "o3-mini" in available_models else available_models[0]
            model_info = "ğŸ’° æœ€æ–°æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆé«˜æ€§èƒ½ãƒ»ä½ã‚³ã‚¹ãƒˆãƒ»æ¨å¥¨ï¼‰"
            st.session_state.selected_model = selected_model
            st.session_state.model_info = model_info
    
    else:
        # å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è¦§é¸æŠ
        selected_model = st.sidebar.selectbox(
            "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            available_models,
            index=0 if "o3-mini" in available_models else 0
        )
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’æ¤œç´¢
        for category, models in model_categories.items():
            if selected_model in models:
                model_info = models[selected_model]['description']
                break
        else:
            model_info = "é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±"
    
    # ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
    if selected_model:
        st.sidebar.success(f"âœ… é¸æŠä¸­: **{selected_model}**")
        st.sidebar.info(model_info)
        
        # ä¾¡æ ¼æƒ…å ±ã‚’è¡¨ç¤º
        for category, models in model_categories.items():
            if selected_model in models:
                price_info = models[selected_model]['price']
                use_case = models[selected_model]['use_case']
                note_info = models[selected_model].get('note', '')
                st.sidebar.markdown(f"ğŸ’° **ä¾¡æ ¼**: {price_info}")
                st.sidebar.markdown(f"ğŸ¯ **é©ç”¨ä¾‹**: {use_case}")
                if note_info:
                    st.sidebar.markdown(f"â„¹ï¸ **çŠ¶æ…‹**: {note_info}")
                break
    
    return selected_model, model_info

def load_conversation_history(csv_file: str = None) -> List[Dict[str, str]]:
    """CSVã‹ã‚‰ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã€OpenAI APIå½¢å¼ã«å¤‰æ›"""
    if not csv_file:
        return []
        
    try:
        df = pd.read_csv(csv_file)
        # NaNå€¤ã‚’å‰Šé™¤
        df = df.dropna()
        messages = []
        
        for _, row in df.iterrows():
            role = "user" if row['side'] == 'human' else "assistant"
            content = str(row['prompt']).strip()
            
            # ç©ºæ–‡å­—åˆ—ã‚„NaNã‚’ã‚¹ã‚­ãƒƒãƒ—
            if content and content != 'nan':
                messages.append({"role": role, "content": content})
        
        return messages
    except FileNotFoundError:
        st.warning(f"{csv_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å±¥æ­´ãªã—ã§ç¶šè¡Œã—ã¾ã™ã€‚")
        return []
    except Exception as e:
        st.error(f"å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def generate_copy_ideas(orientation: str, csv_file: str = None, num_ideas: int = 5, model: str = "gpt-4o") -> str:
    """ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ + ä¼šè©±å±¥æ­´ãƒ™ãƒ¼ã‚¹ã®ã‚³ãƒ”ãƒ¼ç”Ÿæˆ"""
    openai.api_key = OPENAI_API_KEY
    
    # ä¼šè©±å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
    conversation_history = load_conversation_history(csv_file)
    
    # ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã‚’åˆ¤å®š
    is_o1_pro = "o1-pro" in model.lower()
    is_o3_or_o1_other = any(prefix in model.lower() for prefix in ['o1-', 'o3-']) and not is_o1_pro
    
    try:
        if is_o1_pro:
            # o1-proã¯Responses APIã®ã¿å¯¾å¿œ
            user_message = f"""
{orientation}

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€åŠ¹æœçš„ãªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’{num_ideas}å€‹ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
            
            response = openai.responses.create(
                model=model,
                input=user_message,
                reasoning={"effort": "high"}  # o1-proç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            )
            # Responses APIã®æ­£ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼
            return response.choices[0].message.content
            
        elif is_o3_or_o1_other:
            # ãã®ä»–ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆo1ã€o3-miniç­‰ï¼‰ç”¨ã®å‡¦ç†
            user_message = f"""
{orientation}

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€åŠ¹æœçš„ãªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’{num_ideas}å€‹ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
            
            # æ¨è«–ãƒ¢ãƒ‡ãƒ«ã¯å±¥æ­´ã‚’å«ã‚ãšã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿
            messages = [{"role": "user", "content": user_message}]
            
            response = openai.chat.completions.create(
                model=model,
                messages=messages,
                max_completion_tokens=1200
                # temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„
            )
            return response.choices[0].message.content
        
        else:
            # æ¨™æº–GPTãƒ¢ãƒ‡ãƒ«ç”¨ã®å‡¦ç†
            system_message = {
                "role": "system", 
                "content": """ã‚ãªãŸã¯å„ªç§€ãªã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¦ã€ä¸ãˆã‚‰ã‚ŒãŸã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æ´»ç”¨ã—ã€åŠ¹æœçš„ãªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯ç°¡æ½”ã§ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã‚ã‚Šã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«åˆºã•ã‚‹ã‚‚ã®ã‚’5å€‹å³é¸ã—ã¦ãã ã•ã„ã€‚
ã‚³ãƒ”ãƒ¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""
            }
            
            # æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            new_user_message = {
                "role": "user", 
                "content": f"""
{orientation}

æœ€çµ‚çš„ã«{num_ideas}å€‹ã®å³é¸ã•ã‚ŒãŸã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
            }
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…åˆ—ã‚’æ§‹ç¯‰
            messages = [system_message] + conversation_history + [new_user_message]
            
            response = openai.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=1200,
                temperature=0.9
            )
            return response.choices[0].message.content
            
    except Exception as e:
        error_msg = str(e)
        
        # o1-proã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®ç‰¹åˆ¥ãªå‡¦ç†
        if is_o1_pro:
            st.warning(f"âš ï¸ {model}ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚Responses APIè¦æ±‚: {error_msg}")
            fallback_model = "o3-mini"
            st.info(f"ğŸ”„ {fallback_model}ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            return generate_copy_ideas(orientation, csv_file, num_ideas, fallback_model)
        
        # ãã®ä»–ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
        elif is_o3_or_o1_other:
            st.warning(f"âš ï¸ {model}ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}")
            fallback_model = "gpt-4o"
            st.info(f"ğŸ”„ {fallback_model}ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            return generate_copy_ideas(orientation, csv_file, num_ideas, fallback_model)
        
        else:
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"

# Streamlit UI
st.set_page_config(
    page_title="ã‚³ãƒ”ãƒ¼ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼",
    page_icon="âœï¸",
    layout="wide"
)

st.markdown("---")

# ãƒ¢ãƒ‡ãƒ«é¸æŠ
selected_model, model_info = display_model_selector()

st.sidebar.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - ä¼šè©±å±¥æ­´è¨­å®š
st.sidebar.header("ğŸ“ ä¼šè©±å±¥æ­´è¨­å®š")

# CSVãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]
csv_options = ["å±¥æ­´ãªã—"] + csv_files

selected_csv = st.sidebar.selectbox(
    "ä¼šè©±å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
    csv_options,
    index=1 if "interaction_copy_focused.csv" in csv_files else 0
)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“‹ ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å…¥åŠ›")
    
    # ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å…¥åŠ›ã‚¨ãƒªã‚¢
    orientation = st.text_area(
        "ä¼æ¥­æƒ…å ±ãƒ»èª²é¡Œãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç­‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        placeholder="""ä¾‹ï¼š
èª²é¡Œã®ãƒã‚¤ãƒ³ãƒˆ
ä»Šå›ã€å‹Ÿé›†ã™ã‚‹ä½œå“ã«æœŸå¾…ã™ã‚‹ã“ã¨
å½“ç¤¾ã¯ã‚´ãƒ ç´ æã‚’ç”¨ã„ã¦ã€çœŸã«ä¾¡å€¤ã‚ã‚‹è£½å“ã‚’æä¾›ã™ã‚‹ä¼šç¤¾ã§ã‚ã‚ŠãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚

å¸‚å ´ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å‹•å‘
ã€Œå¥½ããªã“ã¨ã‚’ä»•äº‹ã«ã—ãŸã„ã€ã€Œã‚„ã‚ŠãŒã„ã‚„é”æˆæ„Ÿã‚’å¤§åˆ‡ã«ã—ãŸã„ã€ã¨è€ƒãˆã¦ã„ã‚‹å°±è·ãƒ»è»¢è·ã‚’è€ƒãˆã¦ã„ã‚‹è‹¥å¹´å±¤ãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§ã™ã€‚

èª²é¡Œå•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã®è¨´æ±‚ã—ãŸã„ãƒã‚¤ãƒ³ãƒˆ
ã‚´ãƒ ã¯ä»£æ›¿ä¸å¯èƒ½ãªå”¯ä¸€ã®ç´ æã§ã€æœªæ¥ã‚’å‰µé€ ã™ã‚‹å¤§ããªå¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’è¡¨ç¾ã—ã¦ã‚‚ã‚‰ã„ãŸã„ã§ã™ã€‚""",
        height=200
    )
    
    generate_button = st.button("ğŸš€ ã‚³ãƒ”ãƒ¼ç”Ÿæˆ", type="primary")

with col2:
    st.subheader("âœ¨ ç”Ÿæˆçµæœ")
    
    if generate_button:
        if not orientation:
            st.error("ã‚ªãƒªã‚¨ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            # é¸æŠã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
            csv_file = selected_csv if selected_csv != "å±¥æ­´ãªã—" else None
            
            with st.spinner(f"ã‚³ãƒ”ãƒ¼ã‚’ç”Ÿæˆä¸­... (ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {selected_model})"):
                result = generate_copy_ideas(orientation, csv_file, 5, selected_model)
                
            st.success("ç”Ÿæˆå®Œäº†ï¼")
            st.text_area("ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ”ãƒ¼", value=result, height=400)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.download_button(
                label="ğŸ“„ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=result,
                file_name="copy_ideas.txt",
                mime="text/plain"
            )

# é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º
if selected_csv != "å±¥æ­´ãªã—":
    try:
        df = pd.read_csv(selected_csv)
        st.sidebar.info(f"ğŸ“Š å±¥æ­´: {len(df)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
    except:
        st.sidebar.error("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")

st.sidebar.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - ç®¡ç†è€…ç”¨æ©Ÿèƒ½ã®ã¿
st.sidebar.header("ğŸ”§ ç®¡ç†è€…æ©Ÿèƒ½")
if st.sidebar.checkbox("ç®¡ç†è€…ãƒ¢ãƒ¼ãƒ‰", value=False):
    st.sidebar.markdown("---")
    st.sidebar.subheader("ç®¡ç†è€…è¨­å®š")
    
    available_models = get_available_models()
    
    if st.sidebar.button("åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ä¸€è¦§è¡¨ç¤º"):
        st.sidebar.write("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
        for model in available_models:
            st.sidebar.write(f"â€¢ {model}")
    
    if st.sidebar.button("ãƒ¢ãƒ‡ãƒ«è©³ç´°æƒ…å ±è¡¨ç¤º"):
        model_categories = get_model_categories()
        for category, models in model_categories.items():
            st.sidebar.write(f"**{category}**")
            for model_id, model_data in models.items():
                if model_id in available_models:
                    st.sidebar.write(f"â€¢ {model_id}: {model_data['price']}")
    
    if st.sidebar.button("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º"):
        st.sidebar.json({
            "total_generations": 42,
            "avg_generation_time": "3.2ç§’",
            "current_model": selected_model,
            "available_models_count": len(available_models)
        })
        
    # APIè¨­å®šç¢ºèª
    if OPENAI_API_KEY == "sk-proj-your-api-key-here":
        st.sidebar.warning("âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
    else:
        st.sidebar.success("âœ… APIã‚­ãƒ¼ãŒè¨­å®šæ¸ˆã¿") 