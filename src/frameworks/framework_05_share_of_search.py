#!/usr/bin/env python3
"""
ãƒ•ãƒ¬ãƒ¼ãƒ 5: Share of Search åˆ†æ
å®Ÿè¡Œæ–¹æ³•: python framework_05_share_of_search.py
"""

import asyncio
import json
import time
import argparse
from datetime import datetime
from typing import List, Dict, Any
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys

# ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯
try:
    from pytrends.request import TrendReq
except ImportError:
    print("âŒ pytrends ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install pytrends pandas matplotlib")
    sys.exit(1)

class ShareOfSearchFramework:
    """Share of Search åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ - ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ç‰ˆ"""
    
    def __init__(self):
        self.framework_id = 5
        self.framework_name = "Share of Search"
        self.version = "1.0.0"
        self.output_dir = f"data/output/output_framework_05_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"ğŸš€ {self.framework_name} v{self.version} é–‹å§‹")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    async def collect_data(self, brand_name: str, competitors: List[str], 
                          category: str, time_range: str = "today 12-m") -> Dict[str, Any]:
        """Share of Search ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»åˆ†æ"""
        
        start_time = time.time()
        print(f"\nğŸ“Š åˆ†æé–‹å§‹: {brand_name} vs {competitors}")
        
        try:
            # Step 1: Google Trends APIæ¥ç¶š
            print("ğŸ”— Google Trends APIæ¥ç¶šä¸­...")
            pytrends = TrendReq(hl='ja-JP', tz=360, timeout=(10, 25))
            
            # Step 2: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãƒ‡ãƒ¼ã‚¿å–å¾—
            all_keywords = [brand_name] + competitors
            print(f"ğŸ” æ¤œç´¢ãƒ‡ãƒ¼ã‚¿å–å¾—: {all_keywords}")
            
            pytrends.build_payload(all_keywords, timeframe=time_range, geo='JP')
            interest_data = pytrends.interest_over_time()
            
            if interest_data.empty:
                raise Exception("æ¤œç´¢ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            # Step 3: Share of Search è¨ˆç®—
            print("ğŸ§® Share of Search è¨ˆç®—ä¸­...")
            sos_data = self._calculate_share_of_search(interest_data, all_keywords)
            
            # Step 4: ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            trend_analysis = self._analyze_trends(interest_data, all_keywords)
            
            # Step 5: ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ
            competitive_analysis = self._analyze_competitive_position(sos_data, brand_name)
            
            execution_time = time.time() - start_time
            
            result = {
                "framework_info": {
                    "id": self.framework_id,
                    "name": self.framework_name,
                    "version": self.version,
                    "execution_time": execution_time,
                    "timestamp": datetime.now().isoformat()
                },
                "input_parameters": {
                    "brand_name": brand_name,
                    "competitors": competitors,
                    "category": category,
                    "time_range": time_range
                },
                "share_of_search": sos_data,
                "trend_analysis": trend_analysis,
                "competitive_analysis": competitive_analysis,
                "insights": self._generate_insights(sos_data, trend_analysis, competitive_analysis),
                "raw_data_info": {
                    "rows": len(interest_data),
                    "columns": list(interest_data.columns),
                    "date_range": {
                        "start": interest_data.index[0].isoformat() if not interest_data.empty else None,
                        "end": interest_data.index[-1].isoformat() if not interest_data.empty else None
                    }
                },
                "success": True
            }
            
            print(f"âœ… åˆ†æå®Œäº† ({execution_time:.2f}ç§’)")
            return result
            
        except Exception as e:
            error_result = {
                "framework_info": {
                    "id": self.framework_id,
                    "name": self.framework_name,
                    "error": str(e)
                },
                "success": False,
                "execution_time": time.time() - start_time
            }
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return error_result
    
    def _calculate_share_of_search(self, data: pd.DataFrame, keywords: List[str]) -> Dict[str, float]:
        """æ¤œç´¢ã‚·ã‚§ã‚¢è¨ˆç®—"""
        # NaNå€¤ã‚’0ã§ç½®æ›
        data_clean = data[keywords].fillna(0)
        
        # æœŸé–“å¹³å‡ã§ã®å„ãƒ–ãƒ©ãƒ³ãƒ‰ã‚·ã‚§ã‚¢
        total_searches = data_clean.sum(axis=1)
        share_data = {}
        
        for keyword in keywords:
            if total_searches.sum() > 0:
                share_data[keyword] = (data_clean[keyword].sum() / data_clean.sum().sum() * 100)
            else:
                share_data[keyword] = 0.0
        
        return share_data
    
    def _analyze_trends(self, data: pd.DataFrame, keywords: List[str]) -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        trends = {}
        
        for keyword in keywords:
            keyword_data = data[keyword].fillna(0)
            if len(keyword_data) > 1:
                # ç·šå½¢å›å¸°ã§å‚¾å‘è¨ˆç®—
                x = range(len(keyword_data))
                correlation = pd.Series(x).corr(keyword_data)
                
                trend_direction = "increasing" if correlation > 0.1 else "decreasing" if correlation < -0.1 else "stable"
                trend_strength = abs(correlation)
                
                trends[keyword] = {
                    "direction": trend_direction,
                    "strength": trend_strength,
                    "recent_peak": keyword_data.max(),
                    "recent_avg": keyword_data.mean()
                }
        
        return trends
    
    def _analyze_competitive_position(self, sos_data: Dict[str, float], brand_name: str) -> Dict[str, Any]:
        """ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ"""
        sorted_brands = sorted(sos_data.items(), key=lambda x: x[1], reverse=True)
        brand_rank = next((i+1 for i, (brand, _) in enumerate(sorted_brands) if brand == brand_name), None)
        
        market_leader = sorted_brands[0][0] if sorted_brands else None
        brand_share = sos_data.get(brand_name, 0)
        leader_share = sorted_brands[0][1] if sorted_brands else 0
        
        gap_to_leader = leader_share - brand_share if market_leader != brand_name else 0
        
        return {
            "brand_rank": brand_rank,
            "total_brands": len(sos_data),
            "market_leader": market_leader,
            "brand_share": brand_share,
            "leader_share": leader_share,
            "gap_to_leader": gap_to_leader,
            "competitive_intensity": len([s for s in sos_data.values() if s > 10])  # 10%ä»¥ä¸Šã®ãƒ–ãƒ©ãƒ³ãƒ‰æ•°
        }
    
    def _generate_insights(self, sos_data: Dict[str, float], 
                          trend_analysis: Dict[str, Any], 
                          competitive_analysis: Dict[str, Any]) -> List[str]:
        """æ´å¯Ÿç”Ÿæˆ"""
        insights = []
        
        # æ¤œç´¢ã‚·ã‚§ã‚¢æ´å¯Ÿ
        top_brand = max(sos_data.items(), key=lambda x: x[1])
        insights.append(f"æ¤œç´¢ã‚·ã‚§ã‚¢1ä½ã¯{top_brand[0]}ã§{top_brand[1]:.1f}%")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ´å¯Ÿ
        increasing_brands = [brand for brand, data in trend_analysis.items() 
                           if data["direction"] == "increasing" and data["strength"] > 0.3]
        if increasing_brands:
            insights.append(f"ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰: {', '.join(increasing_brands)}")
        
        # ç«¶åˆçŠ¶æ³æ´å¯Ÿ
        if competitive_analysis["competitive_intensity"] > 3:
            insights.append("æ¿€æˆ¦ã‚«ãƒ†ã‚´ãƒªï¼ˆ10%ä»¥ä¸Šã‚·ã‚§ã‚¢ãƒ–ãƒ©ãƒ³ãƒ‰å¤šæ•°ï¼‰")
        
        # ã‚®ãƒ£ãƒƒãƒ—æ´å¯Ÿ
        if competitive_analysis["gap_to_leader"] > 20:
            insights.append(f"ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã®å·®ãŒå¤§ãã„ï¼ˆ{competitive_analysis['gap_to_leader']:.1f}%å·®ï¼‰")
        
        return insights
    
    def save_results(self, result: Dict[str, Any]) -> None:
        """çµæœä¿å­˜"""
        # JSONä¿å­˜ï¼ˆnumpyå‹ã‚’æ¨™æº–Pythonå‹ã«å¤‰æ›ï¼‰
        json_path = os.path.join(self.output_dir, "sos_analysis_result.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=self._json_serializer)
        print(f"ğŸ’¾ çµæœä¿å­˜: {json_path}")
    
    def _json_serializer(self, obj):
        """JSON serialization helper for numpy and pandas types"""
        import numpy as np
        import pandas as pd
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        elif hasattr(obj, 'item'):  # numpy scalars
            return obj.item()
        raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
        
        # CSVä¿å­˜
        if result.get("success") and "share_of_search" in result:
            sos_df = pd.DataFrame(list(result["share_of_search"].items()), 
                                columns=["Brand", "Share_of_Search_%"])
            csv_path = os.path.join(self.output_dir, "share_of_search.csv")
            sos_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ“Š CSVä¿å­˜: {csv_path}")
        
        # å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ä¿å­˜
        if result.get("success"):
            self._save_visualization(result)
    
    def _save_visualization(self, result: Dict[str, Any]) -> None:
        """å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ç”Ÿæˆãƒ»ä¿å­˜"""
        try:
            plt.style.use('default')
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # Share of Search å††ã‚°ãƒ©ãƒ•
            sos_data = result["share_of_search"]
            ax1.pie(sos_data.values(), labels=sos_data.keys(), autopct='%1.1f%%')
            ax1.set_title("Share of Search Distribution")
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘æ£’ã‚°ãƒ©ãƒ•  
            trend_data = result["trend_analysis"]
            brands = list(trend_data.keys())
            strengths = [data["strength"] for data in trend_data.values()]
            colors = ['green' if trend_data[brand]["direction"] == "increasing" 
                     else 'red' if trend_data[brand]["direction"] == "decreasing" 
                     else 'gray' for brand in brands]
            
            ax2.bar(brands, strengths, color=colors)
            ax2.set_title("Trend Strength by Brand")
            ax2.set_ylabel("Trend Strength")
            ax2.tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            
            chart_path = os.path.join(self.output_dir, "sos_analysis_chart.png")
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ ã‚°ãƒ©ãƒ•ä¿å­˜: {chart_path}")
            
        except Exception as e:
            print(f"âš ï¸  ã‚°ãƒ©ãƒ•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def print_summary(self, result: Dict[str, Any]) -> None:
        """çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        if not result.get("success"):
            print(f"\nâŒ å®Ÿè¡Œå¤±æ•—: {result.get('framework_info', {}).get('error', 'Unknown error')}")
            return
        
        print(f"\nğŸ“‹ {self.framework_name} å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 50)
        
        # åŸºæœ¬æƒ…å ±
        print(f"ğŸ¯ å¯¾è±¡ãƒ–ãƒ©ãƒ³ãƒ‰: {result['input_parameters']['brand_name']}")
        print(f"ğŸ†š ç«¶åˆãƒ–ãƒ©ãƒ³ãƒ‰: {', '.join(result['input_parameters']['competitors'])}")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {result['framework_info']['execution_time']:.2f}ç§’")
        
        # Share of Searchçµæœ
        print(f"\nğŸ“Š Share of Searchçµæœ:")
        for brand, share in result["share_of_search"].items():
            print(f"  {brand}: {share:.1f}%")
        
        # ç«¶åˆåˆ†æçµæœ
        comp_analysis = result["competitive_analysis"]
        print(f"\nğŸ† ç«¶åˆãƒã‚¸ã‚·ãƒ§ãƒ³:")
        print(f"  é †ä½: {comp_analysis['brand_rank']}/{comp_analysis['total_brands']}ä½")
        print(f"  å¸‚å ´ãƒªãƒ¼ãƒ€ãƒ¼: {comp_analysis['market_leader']}")
        print(f"  ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã®å·®: {comp_analysis['gap_to_leader']:.1f}%")
        
        # æ´å¯Ÿ
        print(f"\nğŸ’¡ ä¸»è¦æ´å¯Ÿ:")
        for insight in result["insights"]:
            print(f"  â€¢ {insight}")
        
        print(f"\nğŸ“ è©³ç´°çµæœã¯ {self.output_dir} ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
SAMPLE_DATA = {
    "brand_name": "ã‚³ã‚«ã‚³ãƒ¼ãƒ©",
    "competitors": ["ãƒšãƒ—ã‚·", "ä¼Šå³è¡›é–€", "åˆå¾Œã®ç´…èŒ¶"],
    "category": "é£²æ–™",
    "time_range": "today 12-m"
}

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="Share of Search åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯")
    parser.add_argument("--brand", default=SAMPLE_DATA["brand_name"], help="å¯¾è±¡ãƒ–ãƒ©ãƒ³ãƒ‰å")
    parser.add_argument("--competitors", nargs='+', default=SAMPLE_DATA["competitors"], help="ç«¶åˆãƒ–ãƒ©ãƒ³ãƒ‰")
    parser.add_argument("--category", default=SAMPLE_DATA["category"], help="ã‚«ãƒ†ã‚´ãƒª")
    parser.add_argument("--timerange", default=SAMPLE_DATA["time_range"], help="åˆ†ææœŸé–“")
    parser.add_argument("--config", help="è¨­å®šJSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    
    args = parser.parse_args()
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)
        brand_name = config.get("brand_name", args.brand)
        competitors = config.get("competitors", args.competitors)
        category = config.get("category", args.category)
        time_range = config.get("time_range", args.timerange)
    else:
        brand_name = args.brand
        competitors = args.competitors
        category = args.category  
        time_range = args.timerange
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å®Ÿè¡Œ
    framework = ShareOfSearchFramework()
    result = await framework.collect_data(brand_name, competitors, category, time_range)
    
    # çµæœä¿å­˜ãƒ»è¡¨ç¤º
    framework.save_results(result)
    framework.print_summary(result)

if __name__ == "__main__":
    asyncio.run(main()) 